

## Почему React?

Мне было инетесно, каково это - реализовывать приложение, очень тесно взаимодействующее с API браузера, в концепции React. Здесь были актуальными вопросы: где хранить функции для работы с multimeduia API (не в амих же компонентах),как работать с requestAnimationFrame, имея доступ к его созданию и очистке в методах жизненного цикла. Также в интерфейсе присутствуют несколько DOM-элементов, обновляющихся с огромной скоростью (аудио и видео-визуализаторы и информационная панель)

## Файловая структура

      |-- docs собранный проект для github pages
      |-- node_modules - модули, используемые в проекте
      |-- src
        |-- assets - здесь собраны статические файлы (музыка, изображения)
        |-- components - React-компоненты
          |-- AudioPanel - блок для отображения аудио-визуализаторов
          |-- ControlPanel - блок для отображения подсказок пользователю
          |-- InfoPanel - блок для отображения информационной панели
          |-- TerminatorView - блок для отображения обзора теорминатора
          |-- WebcamView - блок для отображения видео с камеры
        |-- multimediaTools -классы для работы с Multimedia API
      |-- .gitignore - игнорируемые файлы
      |-- .MINDS_FLOW.md - описание процеса разработки
      |-- .README.md - описание проекта
      |-- package.json - npm-конфиг

## Описание процесса создания приложения

### 1. Вывод видео на экран

Во-первых, нужно было создать тег видео и связать его с потоком данных, идущих с пользовательской видеокамеры. Для этого использован метод getUserMedia, позволяющий получать поток данных с различных пользовательских устройств. [MDN: about function](https://developer.mozilla.org/en-US/docs/Web/API/Navigator/getUserMedia). 
[Функция для получение промиса, который вернет поток](./src/multimediaTools/WebcamTools/getCameraStream.js). 

Т.к. в последствии  нужно обрабатывать аудио-сигнал, в getUserMedia указываем параметр audio:true. А DOM-элементе `video` устанавливаем свойство muted: true, чтобы аудио-сигнал не выводился на динамики.

### 2 Применение css фильтров к тегу `<video>`

К тегу видео была применена цветокоррекция с помощью установки родительскому для `<video>` элементу фонового цвета, а самому тегу - указания свойства  `mix-blend-mode: color-burn` 


### 3 Борьба за FPS

Даже без цветокоррекции при замере FPS на странице выдается неутешитьное значение 30FPS. Решено попробовать на каждый тик процессора рендерить в изображение из видео в Canvas. [Функция для рендеринга в canvas](./src/multimediaTools/WebcamTools/videoToCanvas.js). Решение было правильным, FPS повышен.

### 4 Наложение шума

Для наложения шума на каждый тик процессора запускается функция, которая пробегается по массиву пикселей полученного с камеры изображения с установленным шагом. Шум применяется к пикселю, если сгенерированное случайное число при делении на индекс пикселя дает остаток 0. [Функция для рендеринга в canvas](./src/multimediaTools/CanvasTools/interferenceToCanvas.js). 

### 5 Измерение параметров аудио

Для измерения параметов аудио сначала был применен алгоритм, доступный с сайта MDN [MDN: пример](https://developer.mozilla.org/ru/docs/Web/API/Web_Audio_API). Однако позже был применен другой алгоритм, позволяющий получать значения громкости в пределах от 0 до 1. 
[Функция для анализа аудио](./src/multimediaTools/AudioTools/audioAnalyser.js).

### 6 Создание информационной панели

Интерфейс выводит на экран три колонки случайно сгенерированных чисел в шестнадцатеричной системе счисления  с заданной скоростью обновления

### 7 Добавление режима прослушивания песни

Дадим терминатору повеселиться, послушав музыку. Реализован режим прослушивания песни, в котором:
 - когда песне играется "бас" -фильтр веб-камеры меняет фон.
 - применяется доп. анимация, будто терминатор трясет головой под музыкую 
 - увеличивается скорость получения информации в интерфейсе
 - анализатор аудио в этом режиме следит не за микрофоном, а за песней.

 При реализации этого режима я столкнулся с наибольшими проблемами. Я хотел воспользоваться функцией [addTrack](https://developer.mozilla.org/en-US/docs/Web/API/MediaStream/addTrack), добавив доп. трек видео-стрим. Однако после долгих часов чтения API, я так и не нашел, как преобразовать имеющийся audio-объект в трек, который можно добавить в поток видео.
 В результате в моей реализации при прослушивании музыки мы просто переключаем текущий аудио-контекст в аудио-панели.
